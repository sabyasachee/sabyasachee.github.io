<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Multimodal Coreference | Sabyasachee Baruah</title> <meta name="author" content="Sabyasachee Baruah"> <meta name="description" content="Annotate person names of face tracks in news videos"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://sabyasachee.github.io/projects/2_multimodal_coreference/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">SabyasacheeÂ </span>Baruah</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Multimodal Coreference</h1> <p class="post-description">Annotate person names of face tracks in news videos</p> </header> <article> <p><em>This work was done as part of a Student Research Internship at Google, Los Angeles, 2022</em></p> <p>The task of multimodal coreference resolution is to map coreferring person mentions in the speech with their face tracks in the video.</p> <p>Consider the following example:</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/projects/2_multimodal_coreference/multimodal-coreference.svg-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/projects/2_multimodal_coreference/multimodal-coreference.svg-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/projects/2_multimodal_coreference/multimodal-coreference.svg-1400.webp"></source> <img src="/assets/img/projects/2_multimodal_coreference/multimodal-coreference.svg" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Multimodal Coreference Resolution" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Example of multimodal coreference resolution in a news video </div> <p>Shown are some video frames and the transcript of a news clip. First, we apply face tracking and text coreference resolution models on the video and the transcript, respectively, to find the face tracks and person mentions. Next, the multimodal coreference resolution model takes these two data streams of different modalities and maps the face tracks to the transcript mentions of the person. For example, the face track of the reporter is mapped to her name: Mario Ocampo.</p> <p><strong>We develop an annotation software to label face tracks with the coreferring person names, and test it on English news videos.</strong></p> <h2 id="annotation-pipeline">Annotation Pipeline</h2> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/projects/2_multimodal_coreference/annotation-software.svg-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/projects/2_multimodal_coreference/annotation-software.svg-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/projects/2_multimodal_coreference/annotation-software.svg-1400.webp"></source> <img src="/assets/img/projects/2_multimodal_coreference/annotation-software.svg" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Annotation Interface" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Annotation interface to label face tracks with person names </div> <p>We follow these steps to label the coreferring person name of the face tracks of a news video.</p> <ol> <li> <p><strong>Face tracks</strong> - We apply a face tracking method to find all face tracks in the news video. As the number of face tracks retrieved is too many to annotate, we sample those that appear on screen for a long period and belong to the foreground main characters. Therefore, we sample at most 10 face tracks, each longer than 2 seconds and occupying greater than 0.5% frame area. We choose these numbers empirically and they will change for a different domain.</p> </li> <li> <p><strong>Person names</strong> - We apply coreference resolution to the transcript of the news video and find the person mentions. We keep the named mentions.</p> </li> <li> <p><strong>Enqueue faces and names</strong> - We overlay bounding boxes on the faces of the sampled face tracks and enqueue the person names to the annotation software.</p> </li> </ol> <p>The above picture shows the annotation interface seen by the labelers. The labelers can view the news clip in the main window. The video slider highlights the frames containing the face track. On the right, the labeler can see the list of names found from the transcript. Their task is to choose the correct coreferring person name for each face track.</p> <h2 id="annotation-results">Annotation Results</h2> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/projects/2_multimodal_coreference/label-face-tracks.svg-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/projects/2_multimodal_coreference/label-face-tracks.svg-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/projects/2_multimodal_coreference/label-face-tracks.svg-1400.webp"></source> <img src="/assets/img/projects/2_multimodal_coreference/label-face-tracks.svg" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Labeling status distribution" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/projects/2_multimodal_coreference/label-reasons.svg-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/projects/2_multimodal_coreference/label-reasons.svg-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/projects/2_multimodal_coreference/label-reasons.svg-1400.webp"></source> <img src="/assets/img/projects/2_multimodal_coreference/label-reasons.svg" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Reasons for labels" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Annotation results of the English news videos. Left - labeling status of the face tracks. Right - how labelers found the person name. </div> <p>We test the annotation pipeline on 1556 English news videos of YouTube-8M dataset. In total, the labelers had to label 14471 face tracks.</p> <p>The annotation results show that the labelers were able to find the coreferring person name for only about a third of the face tracks (left picture). Transcription errors prevented the labeling of 21% of the face tracks. For 34% of the face tracks, the labelers could not find the name from the video, which tells us that <strong>most persons appearing in news videos are never explicitly named</strong>.</p> <p>Taking a closer look at the face tracks successfully labeled, we find that for more than 60% of the labeled face tracks, the labeler found the name displayed on screen. <strong>Therefore, on-screen text, available from optical character recognition, can be a valuable modality for multimodal coreference resolution.</strong></p> <p>Moreover, as expected, others are much more likely, in fact seven times more likely according to our annotation results, to address you by your name over you self-identifying yourself in the context of news videos.</p> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> Â© Copyright 2023 Sabyasachee Baruah. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: October 08, 2023. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>