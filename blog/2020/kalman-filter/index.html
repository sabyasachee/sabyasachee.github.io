<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Kalman Filter | Sabyasachee Baruah</title> <meta name="author" content="Sabyasachee Baruah"> <meta name="description" content="Proof of Kalman Filter"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://sabyasachee.github.io/blog/2020/kalman-filter/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">{
      "title": "Kalman Filter",
      "description": "Proof of Kalman Filter",
      "published": "June 15, 2020",
      "authors": [
        {
          "author": "Sabyasachee Baruah",
          "authorURL": "",
          "affiliations": [
            {
              "name": "University of Southern California",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">SabyasacheeÂ </span>Baruah</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Kalman Filter</h1> <p>Proof of Kalman Filter</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#linear-system">Linear System</a></div> <div><a href="#notations">Notations</a></div> <div><a href="#assumptions">Assumptions</a></div> <div><a href="#kalman-filter">Kalman Filter</a></div> <div><a href="#lemmas">Lemmas</a></div> <div><a href="#proof">Proof</a></div> </nav> </d-contents> <div style="display:none"> $$ \usepackage{amsmath} \usepackage{amssymb} \newcommand{\x}{x_{k}} \newcommand{\xx}{x_{k+1}} \newcommand{\zz}{z_{k+1}} \newcommand{\Q}{Q_{k}} \newcommand{\R}{R_{k+1}} \newcommand{\F}{F_{k}} \newcommand{\G}{G_{k}} \newcommand{\H}{H_{k+1}} \newcommand{\postx}{\hat{x}_{k+1|k+1}} \newcommand{\prex}{\hat{x}_{k+1|k}} \newcommand{\postP}{P_{k+1|k+1}} \newcommand{\preP}{P_{k+1|k}} \newcommand{\Z}{Z_{k}} \newcommand{\ZZ}{Z_{k+1}} \newcommand{\K}{K_{k+1}} \newcommand{\KK}{K'_{k+1}} \newcommand{\var}[1]{E[(#1)(#1)^T]} \newcommand{\cvar}[2]{E[(#1)(#1)^T|#2]} \newcommand{\cvarbreak}[2]{\nonumber E[(#1)\\&amp;\nonumber\quad\quad(#1)^T|#2]} \newcommand{\cvarbreaktwo}[2]{\nonumber E[(#1)\\\nonumber &amp;\quad\quad(#1)^T|#2]} \newcommand{\argmin}[1]{\underset{#1}{\textit{argmin}}\quad} \newcommand{\part}{\frac{\partial}{\partial a_{ij}}} $$ </div> <h2 id="linear-system">Linear System</h2> <p>The figure below shows a discrete-time linear system.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/posts/2020-06-15-kalman-filter/linear-system-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/posts/2020-06-15-kalman-filter/linear-system-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/posts/2020-06-15-kalman-filter/linear-system-1400.webp"></source> <img src="/assets/img/posts/2020-06-15-kalman-filter/linear-system.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Discrete-time linear system </div> <p>\(k\) represents the discrete time instants. \(\x\), \(u_k\) and \(z_k\) represent the state of the system, input to the system and measurement of the system at time \(k\) respectively. The system is governed by the following equations -</p> \[\begin{aligned} \xx &amp;= \F \x + \G u_k + w_k &amp; \text{(State Equation)} \\ \zz &amp;= \H \xx + v_{k+1} &amp; \text{(Sensor Equation)} \end{aligned}\] <p>\(w_k\) is the modeling noise of the state and \(v_k\) is the measurement noise of the sensors. \(x\), \(z\), \(w\) and \(v\) are random variables, and \(u\), \(F\), \(G\) and \(H\) are deterministic. The task of filtering is to obtain an estimate of state \(\x\), given observations \(z_1, z_2, ..., z_k\). The Kalman filter is a linear unbiased estimator which minimizes the mean squared error. We present the proof of Kalman filter here for a discrete-time linear system.</p> <h2 id="notations">Notations</h2> <p>We use the following notations:</p> \[\begin{aligned} Z_k &amp;= z_1, z_2, ..., z_k\\ \hat{x}_{k|j} &amp;= E[x_k | Z_j]\\ P_{k|j} &amp;= Var[x_k|Z_j] = \cvar{x_k - \hat{x}_{k|j}}{Z_j} \end{aligned}\] <h2 id="assumptions">Assumptions</h2> <p>We assume the following:</p> <ol> <li> <p>\(w_k\) and \(v_k\) are zero-mean white noise.</p> \[\begin{aligned} E[w_k] &amp;= \mathbf{0}\\ E[v_k] &amp;= \mathbf{0}\\ Cov[w_k,w_l] = E[w_k w_l^T] &amp;= \begin{cases} \Q &amp; k = l \\ \mathbf{0} &amp; k \neq l \end{cases}\\ Cov[v_k,v_l] = E[v_k v_l^T] &amp;= \begin{cases} R_k &amp; k = l \\ \mathbf{0} &amp; k \neq l \end{cases} \end{aligned}\] <p>\(\Q\) and \(R_k\) are symmetric positive-definite matrices.</p> </li> <li> <p>\(w_k\) and \(v_k\) are uncorrelated with \(\x\) and \(Z_k\).</p> </li> <li> <p>\(E[x_0] = x_{0|0}\) and \(Var[x_0] = \var{x_0 - x_{0|0}} = P_{0|0}\) are the given initial state conditions. \(x_0\) is uncorrelated with \(w_0\) and \(v_0\).</p> </li> </ol> <h2 id="kalman-filter">Kalman Filter</h2> <p>Kalman filter gives a recursive formula for the estimates in prediction and update steps.</p> <p><strong>Prediction</strong></p> \[\begin{aligned} \prex &amp;= \F \hat{x}_{k|k} + \G u_k \\ \preP &amp;= \F P_{k|k} \F^T + \Q \end{aligned}\] <p><strong>Update</strong></p> \[\begin{aligned} \K &amp;= \preP \H^T (\H \preP \H^T + \R)^{-1} \\ \postx &amp;= \prex + \K (\zz - \H \prex) \\ \postP &amp;= (I - \K \H) \preP \end{aligned}\] <p>The Kalman filter propagates the conditional mean and variance of the state, by expressing \(\postx\) and \(\postP\) in terms of \(\hat{x}_{k|k}\) and \(P_{k|k}\).</p> <p>\(\prex\) is the prior estimate of \(\xx\) before observing \(\zz\), and \(\postx\) is the posterior estimate of \(\xx\) after the measurement \(\zz\) of the state. Similarly \(\preP\) and \(\postP\) are the prior and posterior estimates of the variance of the state.</p> <p>\(\K\) is called the Kalman Gain at time \(k + 1\), because it weighs the information gained from the measurement \(\zz\) by taking its difference with the predicted measurement \(\H \prex\).</p> <p>We prove three lemmas in the next section, two of which involve taking the gradient of trace operations and the other concerns with uncorrelated random variables. We use those to prove the Kalman Filter equations in section.</p> <h2 id="lemmas">Lemmas</h2> <h3 id="lemma-1">Lemma 1</h3> <p>\(E[(X + Y)(X + Y)^T] = E[XX^T] + E[YY^T]\), if \(X\) and \(Y\) are uncorrelated, and one of \(E[X]\) or \(E[Y]\) is 0.</p> <details><summary>Proof</summary> <p><strong>Proof</strong></p> <p>\(X\) and \(Y\) are uncorrelated, therefore \(E[XY^T] = E[X]E[Y^T]\). <br> One of \(E[X]\) or \(E[Y]\) equals 0, therefore \(E[XY^T] = 0\).</p> <p>Similarly, \(E[YX^T] = 0\).</p> <p>Expanding \(E[(X + Y)(X + Y)^T]\),</p> \[\begin{aligned} E[(X + Y)(X + Y)^T] &amp;= E[XX^T] + E[YY^T] + E[XY^T] + E[YX^T] \\ &amp;= E[XX^T] + E[YY^T] \qquad (E[XY^T] = E[YX^T] = 0) \end{aligned}\] <p>Therefore \(E[(X + Y)(X + Y)^T] = E[XX^T] + E[YY^T]\).</p> </details> <h3 id="lemma-2">Lemma 2</h3> \[\nabla_A \mathbf{Tr}(AB) = B^T\] <details><summary>Proof</summary> <p><strong>Proof</strong></p> <p>Let \(A = [a]_{n \times p}\) and \(B = [b]_{p \times n}\).</p> \[\begin{aligned} \mathbf{Tr}(AB) &amp;= \sum_{k=1}^{n} (AB)_{kk} = \sum_{k=1}^{n} \sum_{l=1}^{p} a_{kl} b_{lk} \end{aligned}\] <p>Taking gradient with respect to \(a_{ij}\),</p> \[\begin{aligned} \part \mathbf{Tr}(AB) &amp;= \part \sum_{k=1}^{n} \sum_{l=1}^{p} a_{kl} b_{lk} = \sum_{k=1}^{n} \sum_{l=1}^{p} \part a_{kl} b_{lk} \\ &amp;= \part a_{ij} b_{ji} = b_{ji} \end{aligned}\] <p>Therefore \(\nabla_A \mathbf{Tr}(AB) = B^T\).</p> </details> <h3 id="lemma-3">Lemma 3</h3> \[\nabla_A \mathbf{Tr}(ABA^T) = A(B + B^T) \overset{B = B^T}{=} 2AB\] <details><summary>Proof</summary> <p><strong>Proof</strong></p> <p>Let \(A = [a]_{n \times p}\) and \(B = [b]_{p \times p}\).</p> \[\begin{aligned} \mathbf{Tr}(ABA^T) &amp;= \sum_{k=1}^{n} (ABA^T)_{kk} \\ &amp;= \sum_{k=1}^{n} \sum_{l=1}^{p} a_{kl} (BA^T)_{lk}\\ &amp;= \sum_{k=1}^{n} \sum_{l=1}^{p} a_{kl} \sum_{r=1}^{p} b_{lr} (A^T)_{rk}\\ &amp;= \sum_{k=1}^{n} \sum_{l=1}^p \sum_{r=1}^p a_{kl} b_{lr} a_{kr} \end{aligned}\] <p>Taking gradient with respect to \(a_{ij}\),</p> \[\begin{aligned} \part \mathbf{Tr} (ABA^T) &amp;= \part \sum_{k=1}^{n} \sum_{l=1}^p \sum_{r=1}^p a_{kl} b_{lr} a_{kr} \\ &amp;= \sum_{k=1}^{n} \sum_{l=1}^p \sum_{r=1}^p \part a_{kl} b_{lr} a_{kr} \\ &amp;= \sum_{l=1}^p \sum_{r=1}^p \part a_{il} b_{lr} a_{ir} \\ &amp;= \part a_{ij}^2 b_{jj} + \sum_{l=1, l \neq j}^p \part a_{il} b_{lj} a_{ij} + \sum_{r=1, r \neq j}^p \part a_{ij} b_{jr} a_{ir} \\ &amp;= 2 a_{ij} b_{ij} + \sum_{l=1, l \neq j}^p a_{il}b_{lj} + \sum_{r=1,r \neq j}^p b_{jr} a_{ir} \\ &amp;= \sum_{l=1}^p a_{il} b_{lj} + \sum_{r=1}^p a_{ir}b_{jr} \end{aligned}\] <p>Therefore,</p> \[\begin{aligned} \nabla_A \mathbf{Tr} (ABA^T) &amp;= AB + AB^T \\ &amp;= 2AB \quad \text{if } B = B^T \end{aligned}\] </details> <h2 id="proof">Proof</h2> <p><strong>We prove the prediction and update equations of Kalman Filter.</strong></p> <p>Let us rewrite the equations governing the discrete-time linear system.</p> \[\begin{align} \xx &amp;= \F \x + \G u_k + w_k &amp; \text{(State Equation)} \label{state} \\ \zz &amp;= \H \xx + v_{k+1} &amp; \text{(Sensor Equation)} \label{sensor} \end{align}\] <p>We find \(\prex\) using the Kalman Filter state equation.</p> \[\begin{align} \nonumber \prex &amp;= E[x_{k+1} | Z_k] \\ \nonumber &amp;= E[\F \x + \G u_k + w_k | Z_k] &amp; \text{(using Eq \ref{state})} \\ \nonumber &amp;= \F E[\x | Z_k] + \G u_k + E[w_k | Z_k] &amp; \text{($u_k$ is not random)} \\ \nonumber &amp;= \F E[x_k | Z_k] + \G u_k &amp; (E[w_k] = 0) \\ &amp;= \F \hat{x}_{k|k} + \G u_k &amp; \text{(definition of $\hat{x}_{k|k}$)} \label{prex} \end{align}\] <p>We substitute \(\prex\) in the definition of \(\preP\) using equation \ref{prex}.</p> \[\begin{align} \nonumber \preP &amp;= \cvar{\xx - \prex}{Z_k} \\ \nonumber &amp;= \cvarbreaktwo{\F \x + \G u_k + w_k - \F \hat{x}_{k|k} - \G u_k}{Z_k} \\ \nonumber &amp; \qquad \text{(substituting $\xx$ and $\prex$ using Eq \ref{state} and Eq \ref{prex} resp.)} \\ \nonumber &amp;= \cvar{\F (\x - \hat{x}_{k|k}) + w_k}{Z_k} \end{align}\] <p>From definition, we know that \(\hat{x}_{k|k} = g(Z_k)\) for some function \(g\), and \(w_k\) is uncorrelated with \(Z_k\) and \(x_k\).</p> <p>Therefore \(w_k\) is uncorrelated with \(\F (\x - \hat{x}_{k|k})\). \(E[w_k] = 0\), and we can use Lemma 1.</p> \[\begin{align} \nonumber \preP &amp;= \cvar{\F (\x - \hat{x}_{k|k}) + w_k}{Z_k} \\ \nonumber &amp;= \F \cvar{\x - \hat{x}_{k|k}}{Z_k} \F^T + E[w_k w_k^T | Z_k] &amp; \text{(using Lemma 1)} \\ \nonumber &amp;= \F P_{k|k} \F^T + \Q &amp; \text{(definition of $P_{k|k}$ and $\Q$)} \end{align}\] <p>Kalman filter is an unbiased linear optimal estimator. This implies the following:</p> <ol> <li> <p><strong>Unbiased</strong> - The expected value of an unbiased estimator equals the expected value of the parameter. Therefore, \(E[\postx] = E[\xx]\) and \(E[\hat{x}_{k|k}] = E[\x]\).</p> </li> <li> <p><strong>Linear</strong> - A linear estimator means it is a linear combination of the observations, which in this case is \(Z_{k+1}\).</p> <p>\(\prex\) is a function of \(Z_k\). Therefore let \(\postx = \KK\prex + \K \zz\), for some matrix \(\KK\) and \(\K\).</p> </li> <li> <p><strong>Optimal</strong> - The estimator minimizes the mean squared error. Therefore, \(\postx = argmin \; E[(\xx - \postx)^T(\xx - \postx) | \ZZ]\).</p> </li> </ol> <p>We use these three conditions to find \(\K\) and \(\KK\).</p> \[\begin{align} \nonumber E[\xx] &amp;= E[\postx] &amp; \text{($\postx$ is unbiased)} \\ \nonumber &amp;= E[\KK\prex + \K \zz] &amp; \text{($\postx$ is a linear estimator)} \\ \nonumber \nonumber &amp;= \KK E[\F \hat{x}_{k|k} + \G u_k] + \K E[\H \xx + v_{k+1}] \\ \nonumber &amp;\qquad \text{(substituting $\zz$ and $\prex$ using Eq \ref{sensor} and Eq \ref{prex} resp.)} \\ \nonumber &amp;= \KK (\F E[\hat{x}_{k|k}] + \G u_k) + \K \H E[\xx] &amp; (E[v_{k+1}] = 0) \\ \nonumber &amp;= \KK (\F E[\x] + \G u_k) + \K \H E[\xx] &amp; \text{($\hat{x}_{k|k}$ is unbiased)} \\ \nonumber &amp;= \KK E[\F x_k + \G u_k + w_k] + \K \H E[\xx] &amp; (E[w_k] = 0) \\ \nonumber &amp;= \KK E[\xx] + \K \H E[\xx] &amp; \text{(using Eq \ref{state})} \\ \nonumber &amp;= (\KK + \K \H) E[\xx] \\ \nonumber I &amp;= \KK + \K \H \\ \KK &amp;= I - \K \H \label{kdash} \end{align}\] <p>Substituting \(\KK\) in the expression of \(\postx\),</p> \[\begin{align} \nonumber \postx &amp;= \KK \prex + \K \zz \\ \nonumber &amp;= (I - \K \H) \prex + \K \zz &amp; \text{(using Eq \ref{kdash})} \\ &amp;= \prex + \K (\zz - \H \prex) \label{postx} \end{align}\] <p>We substitute \(\postx\) in the definition of \(\postP\) using equation \ref{postx},</p> \[\begin{align} \nonumber \postP &amp;= \cvar{\xx - \postx}{Z_{k+1}} \\ &amp;= \cvarbreaktwo{\xx - \prex - \K (\zz - \H \prex)}{\ZZ} \\ \nonumber &amp;\qquad \text{(substituting $\xx$ using Eq \ref{postx})} \\ &amp;= \cvarbreaktwo{\xx - \prex - \K (\H \xx + v_{k+1} - \H \prex)}{\ZZ} \\ \nonumber &amp;\qquad \text{(substituting $\zz$ using Eq \ref{sensor})} \\ &amp;= \cvarbreak{(I - \K \H) (\xx - \prex) - \K v_{k+1}}{\ZZ} \end{align}\] <p>\(\postx = g(Z_{k+1})\) for some function \(g\), and \(v_{k+1}\) is uncorrelated with \(Z_{k+1}\) and \(x_{k+1}\). Therefore \(\K w_{k+1}\) is uncorrelated with \((I - \K \H) (\xx - \prex)\). \(E[v_{k+1}] = 0\). Therefore we can use Lemma 1.</p> \[\begin{align} \nonumber \postP &amp;= \cvarbreak{(I - \K \H) (\xx - \prex) - \K v_{k+1}}{\ZZ} \\ \nonumber &amp;= (I - \K \H) \cvar{\xx - \prex}{\ZZ} \\ \nonumber &amp;= (I - \K \H)^T + \K E[v_{k+1} v_{k+1}^T | \ZZ] \K^T &amp; \text{(using Lemma 1)} \\ \nonumber \nonumber &amp;= (I - \K \H) \preP (I - \K \H)^T + \K \R \K^T \\ &amp;\qquad \text{(definition of $\preP$ and $\R$)} \label{postP} \end{align}\] <p>We find \(\K\) by minimizing the conditional mean squared error of \(\postx\), \(L = E[(\xx - \postx)^T(\xx - \postx)|\ZZ]\).</p> <p>We express \(L\) as a trace of \(\postP\), and use equation \ref{postP} to write it in terms of \(\K\). We then minimize \(L\) and find \(\K\).</p> \[\begin{align} \nonumber L &amp;= E[(\xx - \postx)^T(\xx - \postx) | \ZZ] \\ \nonumber &amp;= \mathbf{Tr}(\cvar{\xx - \postx}{\ZZ}) \\ \nonumber &amp;= \mathbf{Tr}(\postP) &amp; \text{(definition of $\postP$)} \\ \nonumber &amp;= \mathbf{Tr}((I - \K \H) \preP (I - \K \H)^T + \K \R K^T) &amp; \text{(using Eq \ref{postP})} \\ \nonumber &amp;= \mathbf{Tr}(\; \preP - \preP \H^T \K^T - \K \H \preP \\ \nonumber &amp;\qquad + \K \H \preP \H^T \K^T + \K \R \K^T) \\ \nonumber &amp;= \mathbf{Tr}(\preP) - \mathbf{Tr}(\preP \H^T \K^T) - \mathbf{Tr}(\K \H \preP) \\ \nonumber &amp;\qquad + \mathbf{Tr}(\; \K (\H \preP \H^T + \R) \K^T) &amp; \text{($\mathbf{Tr}$ is a linear operator)} \\ \nonumber &amp;= \mathbf{Tr}(\preP) - \mathbf{Tr}(\K \H \preP) - \mathbf{Tr}(\K \H \preP) \\ \nonumber &amp;\qquad + \mathbf{Tr}(\; \K (\H \preP \H^T + \R) \K^T) &amp; (\mathbf{Tr}(A) = \mathbf{Tr}(A^T)) \\ \nonumber &amp;= \mathbf{Tr}(\preP) - 2 \; \mathbf{Tr}(\K \H \preP) \\ &amp;\qquad + \mathbf{Tr}(\; \K (\H \preP \H^T + \R) \K^T) \label{loss} \end{align}\] <p>Taking the gradient of \(L\) with respect to \(\K\) and setting it equal to 0,</p> \[\begin{align} \nonumber \nabla_{\K} L &amp;= 0 \\ \nonumber 0 &amp;= \nabla_{\K}\; (\mathbf{Tr}(\K (\H \preP \H^T + \R) \K^T) \\ \nonumber &amp;\qquad - 2\; \mathbf{Tr}(\K \H \preP) + \mathbf{Tr}(\preP)) &amp; \text{(using Eq \ref{loss})} \\ \nonumber &amp;= \nabla_{\K}\; (\mathbf{Tr}(\K (\H \preP \H^T + \R) \K^T) \\ \nonumber &amp;\qquad - 2\; \mathbf{Tr}(\K \H \preP)) \\ \nonumber &amp;= 2\;\K (\H \preP \H^T + \R) - 2\; \preP \H^T &amp; \text{(using Lemma 2 and 3)} \\ \therefore\quad \K &amp;= \preP \H^T (\H \preP \H^T + \R)^{-1} \label{kgain} \end{align}\] <p>We can simplify the expression of \(\postP\) in equation \ref{postP} using equation \ref{kgain}.</p> \[\begin{align} \nonumber \postP &amp;= (I - \K \H) \preP (I - \K \H)^T + \K \R \K^T \\ \nonumber &amp;= \preP - \preP \H^T \K^T - \K \H \preP \\ \nonumber &amp;\quad + \K \H \preP \H^T \K^T + \K \R \K^T \\ \nonumber &amp;= \preP - \preP \H^T \K^T - \K \H \preP \\ \nonumber &amp;\quad + \K (\H \preP \H^T + \R) \K^T \\ \nonumber &amp;= \preP - \preP \H^T \K^T - \K \H \preP \\ \nonumber &amp;\quad + \preP \H^T (\H \preP \H^T + \R)^{-1} (\H \preP \H^T + \R) \K^T \\ \nonumber &amp;\qquad \text{(substituing $\K$ using Eq \ref{kgain})} \\ \nonumber &amp;= \preP - \preP \H^T \K^T - \K \H \preP + \preP \H^T \K^T \\ \nonumber &amp;= \preP - \K \H \preP \\ \nonumber &amp;= (I - \K \H) \preP \end{align}\] <p>Arranging all results together,</p> \[\begin{aligned} \prex &amp;= \F \hat{x}_{k|k} + \G u_k \\ \preP &amp;= \F P_{k|k} \F^T + \Q \\ \K &amp;= \preP \H^T (\H \preP \H^T + \R)^{-1} \\ \postx &amp;= \prex + \K (\zz - \H \prex) \\ \postP &amp;= (I - \K \H) \preP \end{aligned}\] </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography> </div> <footer class="fixed-bottom"> <div class="container mt-0"> Â© Copyright 2023 Sabyasachee Baruah. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: November 30, 2023. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>